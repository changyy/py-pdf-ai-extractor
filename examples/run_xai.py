from pdf_ai_extractor.handlers import create_handler
import json
import os
from pathlib import Path

def main():
    handler = create_handler(
        "xai",
        config={
            "api_key": os.getenv("XAI_API_KEY", ""),
            "model": "grok-beta",
            "max_content_length": 8000
        }
    )
    
    result = handler.result('/tmp/LeeDL_Tutorial.pdf')
    
    print(json.dumps(result, ensure_ascii=False, indent=2))

if __name__ == "__main__":
    main()

"""
{
  "abstract": "本教程基于李宏毅教授的《机器学习》（2021年春）课程，旨在为深度学习初学者提供一个轻松入门的中文学习资源。教程内容全面，涵盖了深度学习的基本理论和实践方法，通过幽默风趣的讲解和动漫相关的例子，使深奥的理论变得易于理解。除此之外，教程还补充了其他深度学习相关知识，并对公式进行了详细推导，降低了阅读门槛。作者团队由Datawhale成员组成，具有丰富的学术和实践背景，致力于通过此教程帮助读者深入理解深度学习的各个方面。",
  "keywords": [
    "深度学习",
    "机器学习",
    "李宏毅",
    "教程",
    "中文",
    "入门",
    "强化学习",
    "计算机视觉",
    "时间序列",
    "数据挖掘"
  ],
  "bookmarks": [
    "机器学习基础",
    "案例学习",
    "线性模型",
    "分段线性曲线",
    "模型变形",
    "机器学习框架",
    "实践方法论",
    "模型偏差",
    "优化问题",
    "过拟合",
    "交叉验证",
    "不匹配",
    "深度学习基础",
    "局部极小值与鞍点",
    "临界点及其种类",
    "判断临界值种类的方法",
    "批量和动量",
    "批量大小对梯度下降法的影响",
    "动量法",
    "自适应学习率",
    "AdaGrad",
    "RMSProp",
    "Adam",
    "学习率调度",
    "优化总结",
    "分类",
    "分类与回归的关系",
    "带有 softmax 的分类",
    "分类损失",
    "批量归一化",
    "考虑深度学习",
    "测试时的批量归一化",
    "内部协变量偏移",
    "卷积神经网络",
    "观察1：检测模式不需要整张图像",
    "简化1：感受野",
    "观察2：同样的模式可能会出现在图像的不同区域",
    "简化2：共享参数",
    "简化1和2的总结",
    "观察3：下采样不影响模式检测",
    "简化3：汇聚",
    "卷积神经网络的应用：下围棋",
    "循环神经网络",
    "独热编码",
    "什么是RNN？",
    "RNN架构",
    "其他RNN",
    "Elman 网络 &Jordan 网络",
    "双向循环神经网络",
    "长短期记忆网络",
    "LSTM举例",
    "LSTM运算示例",
    "LSTM原理",
    "RNN学习方式",
    "如何解决RNN梯度消失或者爆炸",
    "RNN其他应用",
    "多对一序列",
    "多对多序列",
    "序列到序列",
    "自注意力机制",
    "输入是向量序列的情况",
    "类型1：输入与输出数量相同",
    "类型2：输入是一个序列，输出是一个标签",
    "类型3：序列到序列",
    "自注意力的运作原理",
    "多头注意力",
    "位置编码",
    "截断自注意力",
    "自注意力与卷积神经网络对比",
    "自注意力与循环神经网络对比",
    "Transformer",
    "序列到序列模型",
    "语音识别、机器翻译与语音翻译",
    "语音合成",
    "聊天机器人",
    "问答任务",
    "句法分析",
    "多标签分类",
    "Transformer结构",
    "Transformer编码器",
    "Transformer解码器",
    "自回归解码器",
    "非自回归解码器",
    "编码器-解码器注意⼒",
    "Transformer的训练过程",
    "序列到序列模型训练常用技巧",
    "复制机制",
    "引导注意力",
    "束搜索",
    "加入噪声",
    "使用强化学习训练",
    "计划采样",
    "生成模型",
    "生成对抗网络",
    "生成器",
    "辨别器",
    "生成器与辨别器的训练过程",
    "GAN的应用案例",
    "GAN的理论介绍",
    "WGAN算法",
    "训练GAN的难点与技巧",
    "GAN的性能评估方法",
    "条件型生成",
    "Cycle GAN",
    "扩散模型",
    "自监督学习",
    "来⾃Transformers的双向编码器表⽰（BERT）",
    "BERT的使用方式",
    "BERT有用的原因",
    "BERT的变种",
    "⽣成式预训练（GPT）",
    "自编码器",
    "自编码器的概念",
    "为什么需要自编码器？",
    "去噪自编码器",
    "自编码器应用之特征解耦",
    "自编码器应用之离散隐表征",
    "自编码器的其他应用",
    "对抗攻击",
    "对抗攻击简介",
    "如何进行网络攻击",
    "快速梯度符号法",
    "白盒攻击与黑盒攻击",
    "其他模态数据被攻击案例",
    "现实世界中的攻击",
    "防御方式中的被动防御",
    "防御方式中的主动防御",
    "迁移学习",
    "领域偏移",
    "领域自适应",
    "领域泛化",
    "强化学习",
    "强化学习应用",
    "玩电子游戏",
    "下围棋",
    "强化学习框架",
    "第1步：未知函数",
    "第2步：定义损失",
    "第3步：优化",
    "评价动作的标准",
    "使用即时奖励作为评价标准",
    "使用累积奖励作为评价标准",
    "使用折扣累积奖励作为评价标准",
    "使用折扣累积奖励减去基线作为评价标准",
    "Actor-Critic",
    "优势 Actor-Critic",
    "元学习",
    "元学习的概念",
    "元学习的三个步骤",
    "元学习与机器学习",
    "元学习的实例算法",
    "元学习的应用",
    "终身学习",
    "灾难性遗忘",
    "终身学习评估方法",
    "终身学习的主要解法",
    "网络压缩",
    "网络剪枝",
    "知识蒸馏",
    "参数量化",
    "网络架构设计",
    "动态计算",
    "可解释性人工智能",
    "可解释性人工智能的重要性",
    "决策树模型的可解释性",
    "可解释性机器学习的目标",
    "可解释性机器学习中的局部解释",
    "可解释性机器学习中的全局解释",
    "扩展与小结",
    "ChatGPT",
    "ChatGPT简介和功能",
    "对于ChatGPT的误解",
    "ChatGPT背后的关键技术——预训练",
    "ChatGPT带来的研究问题",
    "术语"
  ]
}
"""
